\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{url} % not crucial - just used below for the URL 
\usepackage{multirow}
\usepackage{caption}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{booktabs}
%\usepackage{graphicx}
\usepackage{soul}
\usepackage{color}
\usepackage{xspace}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}
\usepackage{xcolor}
\usepackage{url}
\usepackage{pifont}
\usepackage{hyperref}
\usepackage[section]{placeins}
\newcommand{\xmark}{\ding{55}}
% \usepackage[pdftex]{graphicx}
%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{.8in}%
\addtolength{\topmargin}{-1in}%


\begin{document}
{\fontsize{2.5}{4}\selectfont}
%\bibliographystyle{natbib}

% \def\spacingset#1{\renewcommand{\baselinestretch}%
% {#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf 
 Summary of SCAN: Learning to Classify Images without Labels
}
  \author{Rakibuzzaman Mahmud: 1141444{}\\
    Master Seminar: Deep Learning in Computer Vision\\
}
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Title}
\end{center}
  \medskip
} \fi

 \renewcommand{\abstractname}{Overview}

\bigskip
\begin{abstract}

Convolutional neural networks have made breakthroughs in processing image, video, speech, and text and have recently been substantially improving upon the state of the art in image classification. But CNN often achieves their strong performance through supervised learning, which requires a huge amount of labeled dataset. But when there are no labels to train a network how do we get the network to learn meaningful features from the images? 

Combining representation learning with clustering is one of the most promising approaches for unsupervised learning.  The method described in the paper called SCAN(Semantic Clustering by Adopting Nearest neighbors) decouples the feature representation part and the clustering part resulting in a state of the art accuracy. The authors try to solve the problem with 3 steps: 
Self Supervised Learning: a self-supervised task from representation learning tries to extract semantically meaningful features. Clustering: clustering the similar representation using Nearest-neighbor-based Clustering. Self Labelling: using already well-classified images and fixing mistakes through self-labeling. SCAN method is the first to perform well on a large-scale dataset for image classification and shows promising results on ImageNet. Furthermore, it outperforms several semi-supervised learning methods with unlabelled data.

\end{abstract}

\noindent%
{\it Keywords:} Unsupervised Learning, Self-Supervised Learning, Image
Classification, Clustering.
\vfill

\newpage

% \spacingset{1.45} % DON'T change the spacing!

\input{introduction}
\input{related_work}
\input{method}
\input{experiments}
\input{comparison}
\input{conclusion}

\label{sec:meth}

% \begin{figure}


% \caption{The continuous 2D Grid environment, and a proposed agent movement (assuming discrete valued actions). \label{fig:first}}
% \end{figure}


\newpage

\bibliographystyle{unsrt}
\bibliography{citations_suppl}

\end{document}
